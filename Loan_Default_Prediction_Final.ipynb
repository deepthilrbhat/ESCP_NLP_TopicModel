{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loan Default Prediction\n",
    "## Team Members:\n",
    "* Harish Puvvada         - hp1047\n",
    "* Vamsi Mohan Ramineedi  - vmr286\n",
    "\n",
    "Github link: https://github.com/harishpuvvada/LoanDefault-Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing,metrics \n",
    "from IPython.core.display import HTML\n",
    "pd.set_option(\"display.max_columns\",75)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn import linear_model,svm\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<span style=\"color:blue\">\n",
    "> Importing data of Lending club for the years 2012-14\n",
    "</span>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>emp_title</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>issue_d</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>pymnt_plan</th>\n",
       "      <th>url</th>\n",
       "      <th>desc</th>\n",
       "      <th>purpose</th>\n",
       "      <th>title</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>addr_state</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>earliest_cr_line</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>mths_since_last_delinq</th>\n",
       "      <th>mths_since_last_record</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>initial_list_status</th>\n",
       "      <th>out_prncp</th>\n",
       "      <th>out_prncp_inv</th>\n",
       "      <th>total_pymnt</th>\n",
       "      <th>total_pymnt_inv</th>\n",
       "      <th>total_rec_prncp</th>\n",
       "      <th>total_rec_int</th>\n",
       "      <th>total_rec_late_fee</th>\n",
       "      <th>recoveries</th>\n",
       "      <th>collection_recovery_fee</th>\n",
       "      <th>last_pymnt_d</th>\n",
       "      <th>last_pymnt_amnt</th>\n",
       "      <th>next_pymnt_d</th>\n",
       "      <th>last_credit_pull_d</th>\n",
       "      <th>collections_12_mths_ex_med</th>\n",
       "      <th>mths_since_last_major_derog</th>\n",
       "      <th>policy_code</th>\n",
       "      <th>application_type</th>\n",
       "      <th>annual_inc_joint</th>\n",
       "      <th>dti_joint</th>\n",
       "      <th>verification_status_joint</th>\n",
       "      <th>acc_now_delinq</th>\n",
       "      <th>tot_coll_amt</th>\n",
       "      <th>tot_cur_bal</th>\n",
       "      <th>open_acc_6m</th>\n",
       "      <th>open_il_6m</th>\n",
       "      <th>open_il_12m</th>\n",
       "      <th>open_il_24m</th>\n",
       "      <th>mths_since_rcnt_il</th>\n",
       "      <th>total_bal_il</th>\n",
       "      <th>il_util</th>\n",
       "      <th>open_rv_12m</th>\n",
       "      <th>open_rv_24m</th>\n",
       "      <th>max_bal_bc</th>\n",
       "      <th>all_util</th>\n",
       "      <th>total_rev_hi_lim</th>\n",
       "      <th>inq_fi</th>\n",
       "      <th>total_cu_tl</th>\n",
       "      <th>inq_last_12m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1077501</td>\n",
       "      <td>1296599</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>4975.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>10.65</td>\n",
       "      <td>162.87</td>\n",
       "      <td>B</td>\n",
       "      <td>B2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>Verified</td>\n",
       "      <td>Dec-2011</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>n</td>\n",
       "      <td>https://www.lendingclub.com/browse/loanDetail....</td>\n",
       "      <td>Borrower added on 12/22/11 &gt; I need to upgrade...</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>Computer</td>\n",
       "      <td>860xx</td>\n",
       "      <td>AZ</td>\n",
       "      <td>27.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Jan-1985</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13648.0</td>\n",
       "      <td>83.7</td>\n",
       "      <td>9.0</td>\n",
       "      <td>f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5861.071414</td>\n",
       "      <td>5831.78</td>\n",
       "      <td>5000.00</td>\n",
       "      <td>861.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Jan-2015</td>\n",
       "      <td>171.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jan-2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1077430</td>\n",
       "      <td>1314167</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>15.27</td>\n",
       "      <td>59.83</td>\n",
       "      <td>C</td>\n",
       "      <td>C4</td>\n",
       "      <td>Ryder</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "      <td>RENT</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>Dec-2011</td>\n",
       "      <td>Charged Off</td>\n",
       "      <td>n</td>\n",
       "      <td>https://www.lendingclub.com/browse/loanDetail....</td>\n",
       "      <td>Borrower added on 12/22/11 &gt; I plan to use thi...</td>\n",
       "      <td>car</td>\n",
       "      <td>bike</td>\n",
       "      <td>309xx</td>\n",
       "      <td>GA</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Apr-1999</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1687.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1008.710000</td>\n",
       "      <td>1008.71</td>\n",
       "      <td>456.46</td>\n",
       "      <td>435.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>117.08</td>\n",
       "      <td>1.11</td>\n",
       "      <td>Apr-2013</td>\n",
       "      <td>119.66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sep-2013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077175</td>\n",
       "      <td>1313524</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>15.96</td>\n",
       "      <td>84.33</td>\n",
       "      <td>C</td>\n",
       "      <td>C5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>12252.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>Dec-2011</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>n</td>\n",
       "      <td>https://www.lendingclub.com/browse/loanDetail....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>small_business</td>\n",
       "      <td>real estate business</td>\n",
       "      <td>606xx</td>\n",
       "      <td>IL</td>\n",
       "      <td>8.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nov-2001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2956.0</td>\n",
       "      <td>98.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3003.653644</td>\n",
       "      <td>3003.65</td>\n",
       "      <td>2400.00</td>\n",
       "      <td>603.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Jun-2014</td>\n",
       "      <td>649.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jan-2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1076863</td>\n",
       "      <td>1277178</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.49</td>\n",
       "      <td>339.31</td>\n",
       "      <td>C</td>\n",
       "      <td>C1</td>\n",
       "      <td>AIR RESOURCES BOARD</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>49200.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>Dec-2011</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>n</td>\n",
       "      <td>https://www.lendingclub.com/browse/loanDetail....</td>\n",
       "      <td>Borrower added on 12/21/11 &gt; to pay for prop...</td>\n",
       "      <td>other</td>\n",
       "      <td>personel</td>\n",
       "      <td>917xx</td>\n",
       "      <td>CA</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb-1996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5598.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12226.302212</td>\n",
       "      <td>12226.30</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>2209.33</td>\n",
       "      <td>16.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Jan-2015</td>\n",
       "      <td>357.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jan-2015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1075358</td>\n",
       "      <td>1311748</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>12.69</td>\n",
       "      <td>67.79</td>\n",
       "      <td>B</td>\n",
       "      <td>B5</td>\n",
       "      <td>University Medical Group</td>\n",
       "      <td>1 year</td>\n",
       "      <td>RENT</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>Dec-2011</td>\n",
       "      <td>Current</td>\n",
       "      <td>n</td>\n",
       "      <td>https://www.lendingclub.com/browse/loanDetail....</td>\n",
       "      <td>Borrower added on 12/21/11 &gt; I plan on combi...</td>\n",
       "      <td>other</td>\n",
       "      <td>Personal</td>\n",
       "      <td>972xx</td>\n",
       "      <td>OR</td>\n",
       "      <td>17.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Jan-1996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27783.0</td>\n",
       "      <td>53.9</td>\n",
       "      <td>38.0</td>\n",
       "      <td>f</td>\n",
       "      <td>766.9</td>\n",
       "      <td>766.9</td>\n",
       "      <td>3242.170000</td>\n",
       "      <td>3242.17</td>\n",
       "      <td>2233.10</td>\n",
       "      <td>1009.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Jan-2016</td>\n",
       "      <td>67.79</td>\n",
       "      <td>Feb-2016</td>\n",
       "      <td>Jan-2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  member_id  loan_amnt  funded_amnt  funded_amnt_inv       term  \\\n",
       "0  1077501    1296599     5000.0       5000.0           4975.0  36 months   \n",
       "1  1077430    1314167     2500.0       2500.0           2500.0  60 months   \n",
       "2  1077175    1313524     2400.0       2400.0           2400.0  36 months   \n",
       "3  1076863    1277178    10000.0      10000.0          10000.0  36 months   \n",
       "4  1075358    1311748     3000.0       3000.0           3000.0  60 months   \n",
       "\n",
       "   int_rate  installment grade sub_grade                 emp_title emp_length  \\\n",
       "0     10.65       162.87     B        B2                       NaN  10+ years   \n",
       "1     15.27        59.83     C        C4                     Ryder   < 1 year   \n",
       "2     15.96        84.33     C        C5                       NaN  10+ years   \n",
       "3     13.49       339.31     C        C1       AIR RESOURCES BOARD  10+ years   \n",
       "4     12.69        67.79     B        B5  University Medical Group     1 year   \n",
       "\n",
       "  home_ownership  annual_inc verification_status   issue_d  loan_status  \\\n",
       "0           RENT     24000.0            Verified  Dec-2011   Fully Paid   \n",
       "1           RENT     30000.0     Source Verified  Dec-2011  Charged Off   \n",
       "2           RENT     12252.0        Not Verified  Dec-2011   Fully Paid   \n",
       "3           RENT     49200.0     Source Verified  Dec-2011   Fully Paid   \n",
       "4           RENT     80000.0     Source Verified  Dec-2011      Current   \n",
       "\n",
       "  pymnt_plan                                                url  \\\n",
       "0          n  https://www.lendingclub.com/browse/loanDetail....   \n",
       "1          n  https://www.lendingclub.com/browse/loanDetail....   \n",
       "2          n  https://www.lendingclub.com/browse/loanDetail....   \n",
       "3          n  https://www.lendingclub.com/browse/loanDetail....   \n",
       "4          n  https://www.lendingclub.com/browse/loanDetail....   \n",
       "\n",
       "                                                desc         purpose  \\\n",
       "0  Borrower added on 12/22/11 > I need to upgrade...     credit_card   \n",
       "1  Borrower added on 12/22/11 > I plan to use thi...             car   \n",
       "2                                                NaN  small_business   \n",
       "3    Borrower added on 12/21/11 > to pay for prop...           other   \n",
       "4    Borrower added on 12/21/11 > I plan on combi...           other   \n",
       "\n",
       "                  title zip_code addr_state    dti  delinq_2yrs  \\\n",
       "0              Computer    860xx         AZ  27.65          0.0   \n",
       "1                  bike    309xx         GA   1.00          0.0   \n",
       "2  real estate business    606xx         IL   8.72          0.0   \n",
       "3              personel    917xx         CA  20.00          0.0   \n",
       "4              Personal    972xx         OR  17.94          0.0   \n",
       "\n",
       "  earliest_cr_line  inq_last_6mths  mths_since_last_delinq  \\\n",
       "0         Jan-1985             1.0                     NaN   \n",
       "1         Apr-1999             5.0                     NaN   \n",
       "2         Nov-2001             2.0                     NaN   \n",
       "3         Feb-1996             1.0                    35.0   \n",
       "4         Jan-1996             0.0                    38.0   \n",
       "\n",
       "   mths_since_last_record  open_acc  pub_rec  revol_bal  revol_util  \\\n",
       "0                     NaN       3.0      0.0    13648.0        83.7   \n",
       "1                     NaN       3.0      0.0     1687.0         9.4   \n",
       "2                     NaN       2.0      0.0     2956.0        98.5   \n",
       "3                     NaN      10.0      0.0     5598.0        21.0   \n",
       "4                     NaN      15.0      0.0    27783.0        53.9   \n",
       "\n",
       "   total_acc initial_list_status  out_prncp  out_prncp_inv   total_pymnt  \\\n",
       "0        9.0                   f        0.0            0.0   5861.071414   \n",
       "1        4.0                   f        0.0            0.0   1008.710000   \n",
       "2       10.0                   f        0.0            0.0   3003.653644   \n",
       "3       37.0                   f        0.0            0.0  12226.302212   \n",
       "4       38.0                   f      766.9          766.9   3242.170000   \n",
       "\n",
       "   total_pymnt_inv  total_rec_prncp  total_rec_int  total_rec_late_fee  \\\n",
       "0          5831.78          5000.00         861.07                0.00   \n",
       "1          1008.71           456.46         435.17                0.00   \n",
       "2          3003.65          2400.00         603.65                0.00   \n",
       "3         12226.30         10000.00        2209.33               16.97   \n",
       "4          3242.17          2233.10        1009.07                0.00   \n",
       "\n",
       "   recoveries  collection_recovery_fee last_pymnt_d  last_pymnt_amnt  \\\n",
       "0        0.00                     0.00     Jan-2015           171.62   \n",
       "1      117.08                     1.11     Apr-2013           119.66   \n",
       "2        0.00                     0.00     Jun-2014           649.91   \n",
       "3        0.00                     0.00     Jan-2015           357.48   \n",
       "4        0.00                     0.00     Jan-2016            67.79   \n",
       "\n",
       "  next_pymnt_d last_credit_pull_d  collections_12_mths_ex_med  \\\n",
       "0          NaN           Jan-2016                         0.0   \n",
       "1          NaN           Sep-2013                         0.0   \n",
       "2          NaN           Jan-2016                         0.0   \n",
       "3          NaN           Jan-2015                         0.0   \n",
       "4     Feb-2016           Jan-2016                         0.0   \n",
       "\n",
       "   mths_since_last_major_derog  policy_code application_type  \\\n",
       "0                          NaN          1.0       INDIVIDUAL   \n",
       "1                          NaN          1.0       INDIVIDUAL   \n",
       "2                          NaN          1.0       INDIVIDUAL   \n",
       "3                          NaN          1.0       INDIVIDUAL   \n",
       "4                          NaN          1.0       INDIVIDUAL   \n",
       "\n",
       "   annual_inc_joint  dti_joint verification_status_joint  acc_now_delinq  \\\n",
       "0               NaN        NaN                       NaN             0.0   \n",
       "1               NaN        NaN                       NaN             0.0   \n",
       "2               NaN        NaN                       NaN             0.0   \n",
       "3               NaN        NaN                       NaN             0.0   \n",
       "4               NaN        NaN                       NaN             0.0   \n",
       "\n",
       "   tot_coll_amt  tot_cur_bal  open_acc_6m  open_il_6m  open_il_12m  \\\n",
       "0           NaN          NaN          NaN         NaN          NaN   \n",
       "1           NaN          NaN          NaN         NaN          NaN   \n",
       "2           NaN          NaN          NaN         NaN          NaN   \n",
       "3           NaN          NaN          NaN         NaN          NaN   \n",
       "4           NaN          NaN          NaN         NaN          NaN   \n",
       "\n",
       "   open_il_24m  mths_since_rcnt_il  total_bal_il  il_util  open_rv_12m  \\\n",
       "0          NaN                 NaN           NaN      NaN          NaN   \n",
       "1          NaN                 NaN           NaN      NaN          NaN   \n",
       "2          NaN                 NaN           NaN      NaN          NaN   \n",
       "3          NaN                 NaN           NaN      NaN          NaN   \n",
       "4          NaN                 NaN           NaN      NaN          NaN   \n",
       "\n",
       "   open_rv_24m  max_bal_bc  all_util  total_rev_hi_lim  inq_fi  total_cu_tl  \\\n",
       "0          NaN         NaN       NaN               NaN     NaN          NaN   \n",
       "1          NaN         NaN       NaN               NaN     NaN          NaN   \n",
       "2          NaN         NaN       NaN               NaN     NaN          NaN   \n",
       "3          NaN         NaN       NaN               NaN     NaN          NaN   \n",
       "4          NaN         NaN       NaN               NaN     NaN          NaN   \n",
       "\n",
       "   inq_last_12m  \n",
       "0           NaN  \n",
       "1           NaN  \n",
       "2           NaN  \n",
       "3           NaN  \n",
       "4           NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"loan.csv\",skipinitialspace=True)\n",
    "#df2014 = pd.read_csv(os.getenv('FDS')+'LoanStats_2014.csv',low_memory=False,skiprows=1)\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<span style=\"color:blue\">\n",
    "> Merged datasets of 2012-14 <br>\n",
    "> Removed all empty columns ( these are the columns with personal data of the borrowers. These are not disclosed by the company. so we dropped them)<br>\n",
    "> Target variable(Borrower is a Loan defaulter) - encoded to 0 or 1<br>\n",
    "</span>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = pd.concat([df2012_13, df2014]) #merging 2012 to 2014 datasets\n",
    "dataset = dataset.iloc[:,2:111]          #removing empty columns\n",
    "empty_cols = [i for i in range(45,72)]   #more empty columns\n",
    "dataset = dataset.drop(dataset.columns[empty_cols],axis=1)\n",
    "data_with_loanstatus_sliced = dataset[(dataset['loan_status']==\"Fully Paid\") | (dataset['loan_status']==\"Charged Off\")]\n",
    "di = {\"Fully Paid\":0, \"Charged Off\":1}   #converting target variable to boolean\n",
    "Dataset_withBoolTarget= data_with_loanstatus_sliced.replace({\"loan_status\": di})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current shape of dataset : (252971, 45)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>emp_title</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>issue_d</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>pymnt_plan</th>\n",
       "      <th>url</th>\n",
       "      <th>desc</th>\n",
       "      <th>purpose</th>\n",
       "      <th>title</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>addr_state</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>earliest_cr_line</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>mths_since_last_delinq</th>\n",
       "      <th>mths_since_last_record</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>initial_list_status</th>\n",
       "      <th>out_prncp</th>\n",
       "      <th>out_prncp_inv</th>\n",
       "      <th>total_pymnt</th>\n",
       "      <th>total_pymnt_inv</th>\n",
       "      <th>total_rec_prncp</th>\n",
       "      <th>total_rec_int</th>\n",
       "      <th>total_rec_late_fee</th>\n",
       "      <th>recoveries</th>\n",
       "      <th>collection_recovery_fee</th>\n",
       "      <th>last_pymnt_d</th>\n",
       "      <th>last_pymnt_amnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>4975.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>10.65</td>\n",
       "      <td>162.87</td>\n",
       "      <td>B</td>\n",
       "      <td>B2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>Verified</td>\n",
       "      <td>Dec-2011</td>\n",
       "      <td>0</td>\n",
       "      <td>n</td>\n",
       "      <td>https://www.lendingclub.com/browse/loanDetail....</td>\n",
       "      <td>Borrower added on 12/22/11 &gt; I need to upgrade...</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>Computer</td>\n",
       "      <td>860xx</td>\n",
       "      <td>AZ</td>\n",
       "      <td>27.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Jan-1985</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13648.0</td>\n",
       "      <td>83.7</td>\n",
       "      <td>9.0</td>\n",
       "      <td>f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5861.071414</td>\n",
       "      <td>5831.78</td>\n",
       "      <td>5000.00</td>\n",
       "      <td>861.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Jan-2015</td>\n",
       "      <td>171.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>15.27</td>\n",
       "      <td>59.83</td>\n",
       "      <td>C</td>\n",
       "      <td>C4</td>\n",
       "      <td>Ryder</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "      <td>RENT</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>Dec-2011</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>https://www.lendingclub.com/browse/loanDetail....</td>\n",
       "      <td>Borrower added on 12/22/11 &gt; I plan to use thi...</td>\n",
       "      <td>car</td>\n",
       "      <td>bike</td>\n",
       "      <td>309xx</td>\n",
       "      <td>GA</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Apr-1999</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1687.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1008.710000</td>\n",
       "      <td>1008.71</td>\n",
       "      <td>456.46</td>\n",
       "      <td>435.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117.08</td>\n",
       "      <td>1.11</td>\n",
       "      <td>Apr-2013</td>\n",
       "      <td>119.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2400.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>15.96</td>\n",
       "      <td>84.33</td>\n",
       "      <td>C</td>\n",
       "      <td>C5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>12252.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>Dec-2011</td>\n",
       "      <td>0</td>\n",
       "      <td>n</td>\n",
       "      <td>https://www.lendingclub.com/browse/loanDetail....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>small_business</td>\n",
       "      <td>real estate business</td>\n",
       "      <td>606xx</td>\n",
       "      <td>IL</td>\n",
       "      <td>8.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nov-2001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2956.0</td>\n",
       "      <td>98.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3003.653644</td>\n",
       "      <td>3003.65</td>\n",
       "      <td>2400.00</td>\n",
       "      <td>603.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Jun-2014</td>\n",
       "      <td>649.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  funded_amnt  funded_amnt_inv       term  int_rate  installment  \\\n",
       "0     5000.0       5000.0           4975.0  36 months     10.65       162.87   \n",
       "1     2500.0       2500.0           2500.0  60 months     15.27        59.83   \n",
       "2     2400.0       2400.0           2400.0  36 months     15.96        84.33   \n",
       "\n",
       "  grade sub_grade emp_title emp_length home_ownership  annual_inc  \\\n",
       "0     B        B2       NaN  10+ years           RENT     24000.0   \n",
       "1     C        C4     Ryder   < 1 year           RENT     30000.0   \n",
       "2     C        C5       NaN  10+ years           RENT     12252.0   \n",
       "\n",
       "  verification_status   issue_d  loan_status pymnt_plan  \\\n",
       "0            Verified  Dec-2011            0          n   \n",
       "1     Source Verified  Dec-2011            1          n   \n",
       "2        Not Verified  Dec-2011            0          n   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.lendingclub.com/browse/loanDetail....   \n",
       "1  https://www.lendingclub.com/browse/loanDetail....   \n",
       "2  https://www.lendingclub.com/browse/loanDetail....   \n",
       "\n",
       "                                                desc         purpose  \\\n",
       "0  Borrower added on 12/22/11 > I need to upgrade...     credit_card   \n",
       "1  Borrower added on 12/22/11 > I plan to use thi...             car   \n",
       "2                                                NaN  small_business   \n",
       "\n",
       "                  title zip_code addr_state    dti  delinq_2yrs  \\\n",
       "0              Computer    860xx         AZ  27.65          0.0   \n",
       "1                  bike    309xx         GA   1.00          0.0   \n",
       "2  real estate business    606xx         IL   8.72          0.0   \n",
       "\n",
       "  earliest_cr_line  inq_last_6mths  mths_since_last_delinq  \\\n",
       "0         Jan-1985             1.0                     NaN   \n",
       "1         Apr-1999             5.0                     NaN   \n",
       "2         Nov-2001             2.0                     NaN   \n",
       "\n",
       "   mths_since_last_record  open_acc  pub_rec  revol_bal  revol_util  \\\n",
       "0                     NaN       3.0      0.0    13648.0        83.7   \n",
       "1                     NaN       3.0      0.0     1687.0         9.4   \n",
       "2                     NaN       2.0      0.0     2956.0        98.5   \n",
       "\n",
       "   total_acc initial_list_status  out_prncp  out_prncp_inv  total_pymnt  \\\n",
       "0        9.0                   f        0.0            0.0  5861.071414   \n",
       "1        4.0                   f        0.0            0.0  1008.710000   \n",
       "2       10.0                   f        0.0            0.0  3003.653644   \n",
       "\n",
       "   total_pymnt_inv  total_rec_prncp  total_rec_int  total_rec_late_fee  \\\n",
       "0          5831.78          5000.00         861.07                 0.0   \n",
       "1          1008.71           456.46         435.17                 0.0   \n",
       "2          3003.65          2400.00         603.65                 0.0   \n",
       "\n",
       "   recoveries  collection_recovery_fee last_pymnt_d  last_pymnt_amnt  \n",
       "0        0.00                     0.00     Jan-2015           171.62  \n",
       "1      117.08                     1.11     Apr-2013           119.66  \n",
       "2        0.00                     0.00     Jun-2014           649.91  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset_withBoolTarget['loan_status'].value_counts()\n",
    "print(\"Current shape of dataset :\",Dataset_withBoolTarget.shape)\n",
    "Dataset_withBoolTarget.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current shape of dataset : (252971, 45)\n"
     ]
    }
   ],
   "source": [
    "Dataset_withBoolTarget.dropna(thresh = 340000,axis=1) #340000 is minimum number of non-NA values\n",
    "dataset=Dataset_withBoolTarget\n",
    "print(\"Current shape of dataset :\",dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<span style=\"color:blue\">\n",
    "> some more columns were dropped in the below cell. some of them are not related to our target variable and some of them are redundant. <br>\n",
    "</span>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current shape of dataset : (252971, 29)\n"
     ]
    }
   ],
   "source": [
    "del_col_names = [\"delinq_2yrs\",  \"last_pymnt_d\",\"emp_title\", \"term\", \"pymnt_plan\",\"purpose\",\"title\", \"zip_code\", \"verification_status\", \"dti\",\"earliest_cr_line\", \"initial_list_status\", \"out_prncp\",\"pymnt_plan\",\"total_rec_late_fee\", \"out_prncp_inv\", \"issue_d\"] #deleting some more columns\n",
    "dataset = dataset.drop(labels = del_col_names, axis = 1) \n",
    "print(\"Current shape of dataset :\",dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<span style=\"color:blue\">\n",
    "> After indepth research about these rest 52 features, We selected ~20 relevant features using correlation matrix values. After few cells (in this ipython notebook), we used \"RFE (Recursive Feature Elimination)\" and \" PCA(Principle Component Analysis)\" do the actual feature selection.<br>\n",
    "</span>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current shape of dataset : (252971, 9)\n"
     ]
    }
   ],
   "source": [
    "features = ['funded_amnt','emp_length','annual_inc','home_ownership','grade', \"pub_rec\", \"int_rate\", \"open_acc\",'loan_status'] #'sub_grade' #selecting final features #'addr_state''tax_liens',\n",
    "Final_data = dataset[features] #19 features with target var\n",
    "#Final_data[\"int_rate\"] = Final_data[\"int_rate\"].apply(lambda x:float(x[:-1]) ) #reomving % sign, conv to float  - int_rate column\n",
    "Final_data= Final_data.reset_index(drop=True)\n",
    "print(\"Current shape of dataset :\",Final_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<span style=\"color:blue\">\n",
    "> Grade - Borrower's grade given basing on his/her past history - encoded to numerical values. <br>\n",
    "> home_ownership - this is feature in the dataset which had to be encoded to numerical values. <br>\n",
    "> Emp_Length - this feature was not formatted properly. It has some values which was in the format like \"10+years\",\"5years\"...etc. we changed them to numerical values in the below cell.\n",
    "</span>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "replace() missing 1 required positional argument: 'repl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a3e3db580d74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mFinal_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"home_ownership\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFinal_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"home_ownership\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"MORTGAGE\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"RENT\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"OWN\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"OTHER\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"NONE\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"ANY\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mFinal_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"emp_length\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFinal_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"emp_length\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'years'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'<'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'\\+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'n/a'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFinal_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"emp_length\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mFinal_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"emp_length\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFinal_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"emp_length\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: replace() missing 1 required positional argument: 'repl'"
     ]
    }
   ],
   "source": [
    "#Data encoding\n",
    "Final_data['grade'] = Final_data['grade'].map({'A':7,'B':6,'C':5,'D':4,'E':3,'F':2,'G':1})\n",
    "\n",
    "Final_data[\"home_ownership\"] = Final_data[\"home_ownership\"].map({\"MORTGAGE\":6,\"RENT\":5,\"OWN\":4,\"OTHER\":3,\"NONE\":2,\"ANY\":1})\n",
    "\n",
    "Final_data[\"emp_length\"] = Final_data[\"emp_length\"].str.replace({'years':'','year':'',' ':'','<':'','\\+':'','n/a':'0'}, regex=True)\n",
    "print(Final_data[\"emp_length\"])\n",
    "Final_data[\"emp_length\"] = Final_data[\"emp_length\"].apply(lambda x:int(x))\n",
    "print(\"Current shape of dataset :\",Final_data.shape)\n",
    "Final_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling Missing values and Feature scaling \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<span style=\"color:blue\">\n",
    "> We have some important features which have some missing values. We filled those missing those values with the mean of the column. <br>\n",
    "> We scaled the features all the features here using standard scaler. <br>\n",
    "> We sampled our dataset here after infering from the learning curve plotted.\n",
    "</span>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_data.fillna(Final_data.mean(),inplace = True)\n",
    "HTML(Final_data.tail().to_html())\n",
    "print(\"Current shape of dataset :\",Final_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scl = preprocessing.StandardScaler() #instance of preprocessing\n",
    "fields = Final_data.columns.values[:-1]\n",
    "data_clean = pd.DataFrame(scl.fit_transform(Final_data[fields]), columns = fields)\n",
    "data_clean['loan_status'] = Final_data['loan_status']\n",
    "data_clean['loan_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loanstatus_0 = data_clean[data_clean[\"loan_status\"]==0]\n",
    "loanstatus_1 = data_clean[data_clean[\"loan_status\"]==1]\n",
    "subset_of_loanstatus_0 = loanstatus_0.sample(n=5500)\n",
    "subset_of_loanstatus_1 = loanstatus_1.sample(n=5500)\n",
    "data_clean = pd.concat([subset_of_loanstatus_1, subset_of_loanstatus_0])\n",
    "data_clean = data_clean.sample(frac=1).reset_index(drop=True)\n",
    "print(\"Current shape of dataset :\",data_clean.shape)\n",
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<span style=\"color:blue\">\n",
    "Below are correlation values between the features finally selected.\n",
    "</span>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_clean.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<span style=\"color:blue\">\n",
    "> This learning curve clearly shows that our models are not learning anything after ~11,000 samples. So we randomly sampled our dataset and used only 11,000 samples of our dataset.<br>\n",
    "> Note: In the plot, only ~9000 samples are shown because it is a plot for training set.\n",
    "</span>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "X, y = data_clean.iloc[:,:-1].values, data_clean.iloc[:,-1].values\n",
    "title = \"Learning Curves (Logistic Regression)\"\n",
    "# Cross validation with 100 iterations to get smoother mean test and train\n",
    "# score curves, each time with 20% data randomly selected as a validation set.\n",
    "cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n",
    "estimator = linear_model.LogisticRegression()\n",
    "plot_learning_curve(estimator, title, X, y, ylim=(0.75, 0.90), cv=cv, n_jobs=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curve plot function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<span style=\"color:blue\">\n",
    "This is a callable ROC curve plot function. We have used this function to plot ROC Curve for all the models. We have used Seaborn package.\n",
    "</span>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set('talk', 'whitegrid', 'dark', font_scale=1, font='Ricty',rc={\"lines.linewidth\": 2, 'grid.linestyle': '--'})\n",
    "def plotAUC(truth, pred, lab):\n",
    "    fpr, tpr, _ = metrics.roc_curve(truth,pred)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    lw = 2\n",
    "    c = (np.random.rand(), np.random.rand(), np.random.rand())\n",
    "    plt.plot(fpr, tpr, color= c,lw=lw, label= lab +'(AUC = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC curve') #Receiver Operating Characteristic \n",
    "    plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix Viz function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<span style=\"color:blue\">\n",
    "This is a callable Confusion Matrix Visualization function. We have used this function to visualize True positives, True Negatives, False Positives and False Negatives for all the models.\n",
    "</span>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "def plot_confusion_matrix(model, normalize=False): # This function prints and plots the confusion matrix.\n",
    "    cm = confusion_matrix(y_test, model, labels=[0, 1])\n",
    "    classes=[\"Will Pay\", \"Will Default\"]\n",
    "    cmap = plt.cm.Blues\n",
    "    title = \"Confusion Matrix\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        cm = np.around(cm, decimals=3)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_clean.iloc[:,:-1], data_clean.iloc[:,-1], test_size=0.2, random_state=42)\n",
    "bs_train, bs_test = train_test_split(data_clean, test_size = 0.2, random_state=42) #just for bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Feature Selection using RFE (Recursive Feature Elimination) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "# create the RFE model and select 3 attributes\n",
    "clf_LR = linear_model.LogisticRegression(C=1e30)\n",
    "clf_LR.fit(X_train,y_train)\n",
    "rfe = RFE(clf_LR, 10)\n",
    "rfe = rfe.fit(data_clean.iloc[:,:-1].values, data_clean.iloc[:,-1].values)\n",
    "# summarize the selection of the attributes\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)\n",
    "# ['funded_amnt','emp_length','annual_inc','home_ownership','grade',\"last_pymnt_amnt\", \"mort_acc\", \"pub_rec\", \n",
    "# \"int_rate\", \"open_acc\",\"num_actv_rev_tl\",\"mo_sin_rcnt_rev_tl_op\",\"mo_sin_old_rev_tl_op\",\"bc_util\",\"bc_open_to_buy\",\n",
    "#\"avg_cur_bal\",\"acc_open_past_24mths\",'loan_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA (Principal Component Analysis)\n",
    "from sklearn.decomposition import PCA \n",
    "pca = PCA(n_components=10, whiten=True)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "print('Expected Variance is '+ str(explained_variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['funded_amnt','annual_inc','grade',\"last_pymnt_amnt\", \"int_rate\",\n",
    "            \"mo_sin_rcnt_rev_tl_op\",\"mo_sin_old_rev_tl_op\",\"bc_util\",\"bc_open_to_buy\",\"acc_open_past_24mths\",\"loan_status\"]\n",
    "X_train, X_test = X_train[features[:-1]], X_test[features[:-1]]\n",
    "data_clean = data_clean[features]\n",
    "print(X_train.shape)\n",
    "print(data_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataViz = data_clean\n",
    "sns.set_context(context='notebook')\n",
    "fig, ax = plt.subplots(figsize=(10,10)) \n",
    "corr = dataViz.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.tril_indices_from(mask)] = True\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "sns.heatmap(corr, cmap=cmap,linewidths=1, vmin=-1, vmax=1, square=True, cbar=True, center=0, ax=ax, mask=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest with randomized Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<span style=\"color:blue\">\n",
    "Random forest when implemented with randomized search we got the best accuracies and minimum false negatives(predicting borowwer will not default eventhough he will. This might impact on the credibility of the company). We used the randomized search to find the best hyper paramters for the model.\n",
    "</span>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "rf = RandomForestClassifier(criterion='gini', random_state=0)\n",
    "maxFeatures = range(1,data_clean.shape[1]-1)\n",
    "param_dist = dict(max_features=maxFeatures)\n",
    "rand = RandomizedSearchCV(rf, param_dist, cv=10, scoring='accuracy', n_iter=len(maxFeatures), random_state=10)\n",
    "X=data_clean.iloc[:,:-1].values\n",
    "y=data_clean.iloc[:,-1].values\n",
    "rand.fit(X,y)\n",
    "mean_scores = [result.mean_validation_score for result in rand.grid_scores_]\n",
    "#print('Best Accuracy = '+str(rand.best_score_))\n",
    "print(rand.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomForest = RandomForestClassifier(bootstrap=True,criterion = \"gini\",max_features=rand.best_estimator_.max_features,random_state=0 )\n",
    "randomForest.fit(X_train,y_train)\n",
    "rfPredict = randomForest.predict(X_test)\n",
    "rfPredictproba = randomForest.predict_proba(X_test)[:,1] #for ROC curve\n",
    "rfAccuracy = accuracy_score(y_test,rfPredict)\n",
    "roc_score = metrics.roc_auc_score(y_test,rfPredict)\n",
    "print(rfAccuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "width=0.35\n",
    "ax.bar(np.arange(len(features)-1), randomForest.feature_importances_, width, color='r')\n",
    "ax.set_xticks(np.arange(len(randomForest.feature_importances_)))\n",
    "ax.set_xticklabels(X_train.columns.values,rotation=90)\n",
    "plt.title('Feature Importance from DT')\n",
    "ax.set_ylabel('Normalized Gini Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotAUC(y_test,rfPredictproba, 'Random Forest')\n",
    "plt.show()\n",
    "plt.figure(figsize=(6,6))\n",
    "plot_confusion_matrix(rfPredict, normalize=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with Grid Search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<span style=\"color:blue\">\n",
    "Logistic Regression when implemented with grid search we got the best accuracies and minimum false negatives. We used the randomized search to find the best hyper paramters for the model.\n",
    "</span>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "def cross_validation_best_parameters(model, param_grid):\n",
    "    grid = GridSearchCV(model, param_grid,cv=10, scoring='accuracy')\n",
    "    X=data_clean.iloc[:,:-1].values\n",
    "    y=data_clean.iloc[:,-1].values\n",
    "    grid.fit(X,y)\n",
    "    mean_scores = [result.mean_validation_score for result in grid.grid_scores_]\n",
    "    return mean_scores,grid.best_score_,grid.best_estimator_\n",
    "logreg = linear_model.LogisticRegression(random_state=0)\n",
    "c=[0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "param_grid = dict(C=c)\n",
    "mean_scores,Best_Accuracy, Best_classifier = cross_validation_best_parameters(logreg,param_grid)\n",
    "print(\"Best accuracy is \"+ str(Best_Accuracy))\n",
    "print(Best_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_LR = linear_model.LogisticRegression(C=Best_classifier.C)\n",
    "clf_LR.fit(X_train,y_train)\n",
    "LR_Predict = clf_LR.predict_proba(X_test)[:,1]\n",
    "LR_Predict_bin = clf_LR.predict(X_test)\n",
    "LR_Accuracy = accuracy_score(y_test,LR_Predict.round())\n",
    "print(\"Logistic regression accuracy is \",LR_Accuracy)\n",
    "plotAUC(y_test,rfPredictproba, 'Random Forest')\n",
    "plotAUC(y_test,LR_Predict,'Logistic Regression')\n",
    "plt.show()\n",
    "plt.figure(figsize=(6,6))\n",
    "plot_confusion_matrix(LR_Predict_bin, normalize=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines(SVM) with Grid Search CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<span style=\"color:blue\">\n",
    "SVM (Support Vector Machines) when implemented with grid search, we got the best accuracies and minimum false negatives. We used the Grid search to find the best hyper paramters for the model.Later we used this value to find the predictions and plot the ROC curve.\n",
    "</span>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV    ## takes too much time to run this cell.\n",
    "clf_svm = svm.SVC()\n",
    "powers = range(0,5)\n",
    "cs = [10**i for i in powers]\n",
    "param_grid = dict(C=cs)\n",
    "grid = GridSearchCV(clf_svm, param_grid, cv=10, scoring='accuracy')\n",
    "grid.fit(data_clean.iloc[:,:-1].values, data_clean.iloc[:,-1].values)\n",
    "grid_mean_scores = [result.mean_validation_score for result in grid.grid_scores_]# create a list of the mean scores only\n",
    "print(grid.best_params_)\n",
    "print(\"---------------\")\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf_svm = svm.SVC(kernel = \"rbf\", C=grid.best_estimator_.C)\n",
    "clf_svm.fit(X_train.iloc[:,:],y_train)\n",
    "predictions_svm = clf_svm.predict(X_test.iloc[:,:])\n",
    "predictproba_svm = clf_svm.decision_function(X_test.iloc[:,:])\n",
    "SVM_Accuracy = accuracy_score(y_test,predictions_svm)\n",
    "print(\"SVM accuracy is \",SVM_Accuracy)\n",
    "plotAUC(y_test,predictproba_svm, 'SVM')\n",
    "plotAUC(y_test,rfPredictproba, 'Random Forest')\n",
    "plotAUC(y_test,LR_Predict,'Logistic Regression')\n",
    "plt.show()\n",
    "plt.figure(figsize=(6,6))\n",
    "plot_confusion_matrix(predictions_svm, normalize=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors(KNN) with Grid Search CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<span style=\"color:blue\">\n",
    "KNN (K Nearest Neighbors) when implemented with grid search, we got the best accuracies and minimum false negatives. \n",
    "We used the Grid search to find the best hyper paramters for the model.Later we used this value to find the predictions and plot the ROC curve.\n",
    "</span>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN_Acc = knnfunc(2,10) - 74.8 max, 75.7 for 15, 25 - 76.2, 30 - 76.1\n",
    "from sklearn.grid_search import GridSearchCV    ## takes too much time to run this cell.\n",
    "clf_knn = KNeighborsClassifier()\n",
    "k_range = list(range(35, 50))\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "grid = GridSearchCV(clf_knn, param_grid, cv=10, scoring='accuracy')\n",
    "grid.fit(data_clean.iloc[:,:-1].values, data_clean.iloc[:,-1].values)\n",
    "grid_mean_scores = [result.mean_validation_score for result in grid.grid_scores_]# create a list of the mean scores only\n",
    "print(grid.best_params_)\n",
    "print(\"---------------\")\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"\",grid.best_params_['n_neighbors'])\n",
    "clf_knn_final = KNeighborsClassifier(n_neighbors=grid.best_params_['n_neighbors'])   #taking the the best from the above cell and using it to find predictions\n",
    "clf_knn_final.fit(X_train,y_train)\n",
    "knn_pred = clf_knn_final.predict(X_test)\n",
    "knn_predictproba = clf_knn_final.predict_proba(X_test)[:,1]\n",
    "KNN_Acc = accuracy_score(y_test,knn_pred)\n",
    "print(\"KNN accuracy is \",KNN_Acc)\n",
    "plotAUC(y_test,rfPredictproba, 'Random Forest')\n",
    "plotAUC(y_test,LR_Predict,'Logistic Regression')\n",
    "plotAUC(y_test,predictproba_svm, 'SVM')\n",
    "plotAUC(y_test,knn_predictproba,'K Nearest Neighbors')\n",
    "plt.show()\n",
    "plt.figure(figsize=(6,6))\n",
    "plot_confusion_matrix(knn_pred, normalize=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<span style=\"color:blue\">\n",
    "Our accuracy increased by 2 percent after using grid search and randomized search cross validation techniques. we have tried following ensemble algorithms to check if they can give better results. <br>\n",
    "Bagging : <br>\n",
    "> Create many random sub-samples of our dataset with replacement. <br>\n",
    "> Train a CART(Classfication and Regression Trees) model on each sample.   <br>\n",
    "> Given a new dataset, calculate the average prediction from each model <br>\n",
    "</span>\n",
    "</p>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "num_trees = 100\n",
    "model = BaggingClassifier(base_estimator=randomForest, n_estimators=num_trees, random_state=seed)\n",
    "results = model_selection.cross_val_score(model, data_clean.iloc[:,:-1].values, data_clean.iloc[:,-1].values, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "#num_trees = 100\n",
    "model = BaggingClassifier(base_estimator=clf_LR, random_state=seed)\n",
    "results = model_selection.cross_val_score(model, data_clean.iloc[:,:-1].values, data_clean.iloc[:,-1].values, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ada Boost classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<span style=\"color:blue\">\n",
    "Ada Boost is one of the most commonly used ensemble algorithms. <br>\n",
    "It works by weighting instances in the dataset by how easy or difficult they are to classify, allowing the algorithm to pay or or less attention to them in the construction of subsequent models. <br>\n",
    "</span>\n",
    "</p>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "Ada_clf = AdaBoostClassifier(n_estimators=50)\n",
    "scores = cross_val_score(Ada_clf, data_clean.iloc[:,:-1].values, data_clean.iloc[:,-1].values)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<span style=\"color:blue\">\n",
    "A multilayer perceptron (MLP) is a feedforward artificial neural network. An MLP consists of at least three layers of nodes. MLP utilizes a supervised learning technique called backpropagation for training.Its multiple layers and non-linear activation distinguish MLP from a linear perceptron. It can distinguish data that is not linearly separable. We got our highest accuracy for MLP classifier(little higher than Logistic Regression with Grid Search CV).\n",
    "</span>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf_NN = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1)\n",
    "clf_NN.fit(X_train,y_train)     \n",
    "predict_NN = clf_NN.predict(X_test)\n",
    "predictproba_NN = clf_NN.predict_proba(X_test)[:,1]\n",
    "NNAccuracy = accuracy_score(y_test,predict_NN)\n",
    "print(NNAccuracy)\n",
    "plotAUC(y_test,rfPredictproba, 'Random Forest')\n",
    "plotAUC(y_test,LR_Predict,'Logistic Regression')\n",
    "plotAUC(y_test,predictproba_svm, 'SVM')\n",
    "plotAUC(y_test,knn_predictproba,'K Nearest Neighbors')\n",
    "plotAUC(y_test,predictproba_NN,'MLP')\n",
    "plt.show()\n",
    "plt.figure(figsize=(6,6))\n",
    "plot_confusion_matrix(predict_NN, normalize=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision,recall,F1score for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"RF\",classification_report(y_test, rfPredict, target_names=None))\n",
    "print(\"SVM\",classification_report(y_test, predictions_svm, target_names=None))\n",
    "print(\"LR\",classification_report(y_test, LR_Predict_bin, target_names=None))\n",
    "print(\"KNN\",classification_report(y_test, knn_pred, target_names=None))\n",
    "print(\"MLP\",classification_report(y_test, predict_NN, target_names=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behaviour of models with different sample sizes of dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<span style=\"color:blue\">\n",
    "Here we have plotted ROC_AUC_Score for different sample sizes similar to what we have done in one of the assignments.\n",
    "</span>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modBootstrapper(train, test, nruns, sampsize, model, c):\n",
    "    target = 'loan_status'\n",
    "    aucs_boot = []\n",
    "    for i in range(nruns):\n",
    "        train_samp = train.iloc[np.random.randint(0, len(train), size = sampsize)] #selecting random indexes for KFold\n",
    "        if (model == \"LR\"):\n",
    "            lr_i = linear_model.LogisticRegression(C = 1e30)\n",
    "            lr_i.fit(train_samp.drop(target,1), train_samp[target]) #Logistic regression\n",
    "            p = lr_i.predict_proba(test.drop(target,1))[:,1]\n",
    "        elif (model == \"SVM\"):\n",
    "            svm_i = svm.SVC(kernel='rbf', C = c) \n",
    "            svm_i.fit(train_samp.drop(target,1), train_samp[target])#SVM fitting and predicting if lr==0\n",
    "            p = svm_i.decision_function(test.drop(target,1))\n",
    "        elif (model == \"RF\"):\n",
    "            RF_i = RandomForestClassifier(bootstrap=True,criterion = \"gini\")\n",
    "            RF_i.fit(train_samp.drop(target,1), train_samp[target])\n",
    "            p = RF_i.predict_proba(X_test)[:,1]\n",
    "        elif (model == \"KNN\"):\n",
    "            knn_i = KNeighborsClassifier(n_neighbors= 30) #taking the the best from the above cell and using it to find predictions\n",
    "            knn_i.fit(train_samp.drop(target,1), train_samp[target])\n",
    "            p = knn_i.predict_proba(X_test)[:,1]\n",
    "            \n",
    "        aucs_boot.append(metrics.roc_auc_score(test[target], p)) #calculating auc scores for each bag in bootstrapping\n",
    "    \n",
    "    return [np.mean(aucs_boot), np.sqrt(np.var(aucs_boot))] #mean, standard error = square root of variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bs_train, bs_test = train_test_split(data_clean, test_size = 0.2, random_state=42) #just for bootstrapping\n",
    "SampleSizes = [250,1000,1500,2000,2750,3750,4500,5200,6500,7000,8000,8500,9000,10000,11000] #various samples of Dataset\n",
    "LR_means = []\n",
    "Lr_stderr = []\n",
    "svm_means = []\n",
    "svm_stderr = []\n",
    "RF_means = []\n",
    "RF_stderr = []\n",
    "KNN_means = []\n",
    "KNN_stderr = []\n",
    "for n in SampleSizes:\n",
    "    mean, err = modBootstrapper(bs_train, bs_test, 20, n, \"LR\", 0.1)# collecting means and stderrs for LR model\n",
    "    LR_means.append(mean)\n",
    "    Lr_stderr.append(err)\n",
    "    mean2, err2 = modBootstrapper(bs_train, bs_test, 20, n,\"SVM\", 0.1)# collecting means and stderrs for SVM model\n",
    "    svm_means.append(mean2)\n",
    "    svm_stderr.append(err2)\n",
    "    mean3, err3 = modBootstrapper(bs_train, bs_test, 20, n,\"RF\", 0.1)# collecting means and stderrs for SVM model\n",
    "    RF_means.append(mean3)\n",
    "    RF_stderr.append(err3)\n",
    "    mean4, err4 = modBootstrapper(bs_train, bs_test, 20, n,\"KNN\", 0.1)# collecting means and stderrs for SVM model\n",
    "    KNN_means.append(mean4)\n",
    "    KNN_stderr.append(err4)\n",
    "    print(n)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.log2(SampleSizes), LR_means, 'r', label = 'LR means')\n",
    "plt.plot(np.log2(SampleSizes), LR_means + np.array(Lr_stderr), 'r+-', label = 'LR means + stderr')\n",
    "plt.plot(np.log2(SampleSizes), LR_means - np.array(Lr_stderr), 'r--',  label = 'LR means + stderr')\n",
    "\n",
    "plt.plot(np.log2(SampleSizes), svm_means, 'g', label = 'SVM means')\n",
    "plt.plot(np.log2(SampleSizes), svm_means + np.array(svm_stderr), 'g+-', label = 'SVM means + stderr')\n",
    "plt.plot(np.log2(SampleSizes), svm_means - np.array(svm_stderr), 'g--', label = 'SVM means - stderr')\n",
    "\n",
    "plt.plot(np.log2(SampleSizes), RF_means, 'b', label = 'RF means')\n",
    "plt.plot(np.log2(SampleSizes), RF_means + np.array(RF_stderr), 'b+-', label = 'RF means + stderr')\n",
    "plt.plot(np.log2(SampleSizes), RF_means - np.array(RF_stderr), 'b--', label = 'RF means - stderr')\n",
    "\n",
    "plt.plot(np.log2(SampleSizes), KNN_means, 'm', label = 'KNN means')\n",
    "plt.plot(np.log2(SampleSizes), KNN_means + np.array(KNN_stderr), 'm+-', label = 'KNN means + stderr')\n",
    "plt.plot(np.log2(SampleSizes), KNN_means - np.array(KNN_stderr), 'm--', label = 'KNN means - stderr')\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.20, 0.5),loc = 10)\n",
    "plt.xlabel('Log2(Sample Sizes)')\n",
    "plt.ylabel('roc_auc_score')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
