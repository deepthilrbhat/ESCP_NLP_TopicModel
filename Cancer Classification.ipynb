{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/deepashree/anaconda3/lib/python3.6/site-packages (0.24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /Users/deepashree/anaconda3/lib/python3.6/site-packages (from pandas) (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /Users/deepashree/anaconda3/lib/python3.6/site-packages (from pandas) (1.16.2)\n",
      "Requirement already satisfied: pytz>=2011k in /Users/deepashree/anaconda3/lib/python3.6/site-packages (from pandas) (2018.9)\n",
      "Requirement already satisfied: six>=1.5 in /Users/deepashree/anaconda3/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/deepashree/anaconda3/lib/python3.6/site-packages (1.13.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /Users/deepashree/anaconda3/lib/python3.6/site-packages (from tensorflow) (1.0.7)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /Users/deepashree/anaconda3/lib/python3.6/site-packages (from tensorflow) (1.19.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/deepashree/anaconda3/lib/python3.6/site-packages (from tensorflow) (0.33.1)\n",
      "Requirement already satisfied: astor>=0.6.0 in /Users/deepashree/anaconda3/lib/python3.6/site-packages (from tensorflow) (0.7.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /Users/deepashree/anaconda3/lib/python3.6/site-packages (from tensorflow) (1.0.9)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /Users/deepashree/anaconda3/lib/python3.6/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /Users/deepashree/anaconda3/lib/python3.6/site-packages (from tensorflow) (1.13.1)\n",
      "Requirement already satisfied: gast>=0.2.0 in /Users/deepashree/anaconda3/lib/python3.6/site-packages (from tensorflow) (0.2.2)\n",
      "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /Users/deepashree/anaconda3/lib/python3.6/site-packages (from tensorflow) (1.13.0)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /Users/deepashree/anaconda3/lib/python3.6/site-packages (from tensorflow) (0.7.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/deepashree/anaconda3/lib/python3.6/site-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/deepashree/anaconda3/lib/python3.6/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/deepashree/anaconda3/lib/python3.6/site-packages (from tensorflow) (1.16.2)\n",
      "Requirement already satisfied: h5py in /Users/deepashree/anaconda3/lib/python3.6/site-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n",
      "Requirement already satisfied: setuptools in /Users/deepashree/anaconda3/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow) (40.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/deepashree/anaconda3/lib/python3.6/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/deepashree/anaconda3/lib/python3.6/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: mock>=2.0.0 in /Users/deepashree/anaconda3/lib/python3.6/site-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: pbr>=0.11 in /Users/deepashree/anaconda3/lib/python3.6/site-packages (from mock>=2.0.0->tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (5.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/deepashree/anaconda3/lib/python3.6/site-packages (1.16.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancerDataSet = pd.read_csv(\"BreastCancerWisconsinDataSet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.4601                  0.11890  \n",
       "1          0.2750                  0.08902  \n",
       "2          0.3613                  0.08758  \n",
       "3          0.6638                  0.17300  \n",
       "4          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancerDataSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = cancerDataSet['diagnosis'].map(lambda d: 1 if d == 'M' else 0).values\n",
    "X = cancerDataSet.drop(['diagnosis', 'id'], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.057e+01, 1.777e+01, 1.329e+02, 1.326e+03, 8.474e-02, 7.864e-02,\n",
       "       8.690e-02, 7.017e-02, 1.812e-01, 5.667e-02, 5.435e-01, 7.339e-01,\n",
       "       3.398e+00, 7.408e+01, 5.225e-03, 1.308e-02, 1.860e-02, 1.340e-02,\n",
       "       1.389e-02, 3.532e-03, 2.499e+01, 2.341e+01, 1.588e+02, 1.956e+03,\n",
       "       1.238e-01, 1.866e-01, 2.416e-01, 1.860e-01, 2.750e-01, 8.902e-02])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition the input data into a training set and a test set\n",
    "m = X.shape[0]\n",
    "m_train = 400\n",
    "m_test = m - m_train\n",
    "\n",
    "X_train = X[:m_train]\n",
    "y_train = y[:m_train]\n",
    "\n",
    "X_test = X[m_train:]\n",
    "y_test = y[m_train:]\n",
    "\n",
    "# Gets a batch of the training data. \n",
    "# NOTE: Rather than loading a whole large data set as above and then taking array slices as done here, \n",
    "#       This method can connect to a data source and select just the batch needed.\n",
    "def get_training_batch(batch_num, batch_size):\n",
    "    lower = batch_num * (m_train // batch_size)\n",
    "    upper = lower + batch_size\n",
    "    return X_train[lower:upper], y_train[lower:upper]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Make this notebook's output stable across runs\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# A method to build a new neural net layer of a given size,  \n",
    "# fully connect it to a given preceding layer X, and \n",
    "# compute its output Z either with or without (default) an activation function\n",
    "# Call with activation=tf.nn.relu or tf.nn.sigmoid or tf.nn.tanh, for examples\n",
    "\n",
    "def make_nn_layer(layer_name, layer_size, X, activation=None):\n",
    "    with tf.name_scope(layer_name):\n",
    "        X_size = int(X.get_shape()[1])\n",
    "        SD = 2 / np.sqrt(X_size)\n",
    "        weights = tf.truncated_normal((X_size, layer_size), dtype=tf.float64, stddev=SD)\n",
    "        W = tf.Variable(weights, name='weights')\n",
    "        b = tf.Variable(tf.zeros([layer_size], dtype=tf.float64), name='biases')\n",
    "        Z = tf.matmul(X, W) + b\n",
    "        if activation is not None:\n",
    "            return activation(Z)\n",
    "        else:\n",
    "            return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "WARNING:tensorflow:From /Users/deepashree/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Make the neural net structure\n",
    "n = int(X.shape[1])\n",
    "print(n)\n",
    "n_inputs = n\n",
    "n_hidden1 = 10\n",
    "n_hidden2 = 5\n",
    "n_outputs = 2   # Two output classes: malignant or non-malignant\n",
    "\n",
    "X = tf.placeholder(tf.float64, shape=(None, n_inputs), name='X')\n",
    "\n",
    "with tf.name_scope('nn'):\n",
    "    hidden1 = make_nn_layer('hidden1', n_hidden1, X, activation=tf.nn.relu)\n",
    "    hidden2 = make_nn_layer('hidden2', n_hidden2, hidden1, activation=tf.nn.relu)\n",
    "    outputs = make_nn_layer('outputs', n_outputs, hidden2) \n",
    "    outputs = tf.identity(outputs, \"nn_output\")\n",
    "    \n",
    "y = tf.placeholder(tf.int64, shape=(None), name='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define how the neural net will learn\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=outputs)\n",
    "    loss = tf.reduce_mean(xentropy, name='l')\n",
    "    \n",
    "learning_rate = 0.0001\n",
    "with tf.name_scope(\"train\"):\n",
    "#    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    \n",
    "with tf.name_scope(\"test\"):\n",
    "    correct = tf.nn.in_top_k(tf.cast(outputs, tf.float32), y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the ability to save and restore the trained neural net...\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 Training accuracy: 0.4325 Testing accuracy: 0.23076923\n",
      "200 Training accuracy: 0.8725 Testing accuracy: 0.7751479\n",
      "300 Training accuracy: 0.87 Testing accuracy: 0.7751479\n",
      "400 Training accuracy: 0.875 Testing accuracy: 0.7751479\n",
      "500 Training accuracy: 0.875 Testing accuracy: 0.7751479\n",
      "600 Training accuracy: 0.88 Testing accuracy: 0.7810651\n",
      "700 Training accuracy: 0.875 Testing accuracy: 0.78698224\n",
      "800 Training accuracy: 0.875 Testing accuracy: 0.8165681\n",
      "900 Training accuracy: 0.885 Testing accuracy: 0.83431953\n",
      "1000 Training accuracy: 0.8875 Testing accuracy: 0.84615386\n",
      "\n",
      "Actual classes:    [1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0\n",
      " 0 0 0]\n",
      "Predicted classes: [1 1 0 0 0 0 1 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0\n",
      " 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# TRAINING TIME\n",
    "\n",
    "# This is how many times to use the full set of training data\n",
    "n_epochs = 1000\n",
    "\n",
    "# For a larger training set, it's typically necessary to break training into\n",
    "# batches so only the memory needed to store one batch of training data is used\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as training_session:\n",
    "    init.run()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        # Loop through the whole training set in batches\n",
    "        for batch_num in range(m_train // batch_size):\n",
    "            X_batch, y_batch = get_training_batch(batch_num, batch_size)\n",
    "            training_session.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "\n",
    "        if epoch % 100 == 99:\n",
    "            acc_train = accuracy.eval(feed_dict={X: X_train, y: y_train})\n",
    "            acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "            print(epoch+1, \"Training accuracy:\", acc_train, \"Testing accuracy:\", acc_test)\n",
    "\n",
    "    save_path = saver.save(training_session, \".\\CancerNN\")\n",
    "    \n",
    "    # A quick test with the trained model \n",
    "    Z = outputs.eval(feed_dict={X: X_test[:40]})\n",
    "    y_pred = np.argmax(Z, axis=1)\n",
    "    print(\"\")\n",
    "    print(\"Actual classes:   \", y_test[:40])  \n",
    "    print(\"Predicted classes:\", y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-3b2d1afcdb90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRMSprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Activation, Dense, Dropout, Input\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from numpy.random import seed\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_train[0])\n",
    "print(y_train[0])\n",
    "print(X_train[5])\n",
    "print(y_train[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "Inputs = Input(shape=(30,))\n",
    "Dense_1 = Dense(30)(Inputs)\n",
    "Dense_2 = Dense(30, activation=\"relu\")(Dense_1)\n",
    "Dense_3 = Dense(30, activation=\"relu\")(Dense_2)\n",
    "Dense_4 = Dense(2, activation=\"linear\")(Dense_3)\n",
    "Classifier = Activation('softmax')(Dense_4)\n",
    "\n",
    "model = Model(input=Inputs, output=Classifier)\n",
    "model.summary()\n",
    "\n",
    "#optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, amsgrad=False)\n",
    "optimizer = RMSprop(lr=0.0001)\n",
    "    \n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    " \n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    " \n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
